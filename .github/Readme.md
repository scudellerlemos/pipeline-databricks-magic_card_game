# ğŸš€ CI/CD Pipeline - Databricks MTG

Este documento explica como configurar e usar o pipeline de CI/CD para automatizar o deploy do pipeline de dados do Magic: The Gathering no Databricks.


## ğŸ“‹ PrÃ©-requisitos

### âœ… O que vocÃª precisa ter:

1. **Conta no Databricks** com permissÃµes de administrador
2. **Token de acesso do Databricks** (Personal Access Token)
3. **RepositÃ³rio GitHub** configurado
4. **Secrets configurados no GitHub**

### ğŸ”‘ PermissÃµes NecessÃ¡rias:

- **Databricks**: Admin ou Workspace Admin
- **GitHub**: Owner ou Admin do repositÃ³rio
- **GitHub Actions**: PermissÃ£o para executar workflows

---

## ğŸ”§ ConfiguraÃ§Ã£o dos Secrets

### 1. Crie um Ambiente no GitHub

1. VÃ¡ para `Settings` > `Environments`
2. Clique em `New environment`
3. Nome: `Databricks`
4. Clique em `Configure environment`

### 2. Configure os Secrets no Ambiente

1. No ambiente `Databricks`, vÃ¡ para `Environment secrets`
2. Clique em `Add secret`

### 3. Configure os secrets necessÃ¡rios

| Secret Name | DescriÃ§Ã£o | Exemplo |
|-------------|-----------|---------|
| `DATABRICKS_HOST` | URL do workspace do Databricks | `https://adb-xxxxxxxx.xx.azuredatabricks.net` |
| `DATABRICKS_TOKEN` | Personal Access Token do Databricks | `dapiXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX` |

### 4. Como obter o DATABRICKS_TOKEN

1. No Databricks, vÃ¡ para `User Settings` (Ã­cone de usuÃ¡rio)
2. Clique em `Developer`
3. Clique em `Generate new token`
4. Copie o token gerado
5. **âš ï¸ Importante**: Guarde o token em local seguro, ele nÃ£o serÃ¡ mostrado novamente

---

## ğŸš€ Como Funciona o CI/CD

### ğŸ”„ Fluxo de ExecuÃ§Ã£o

```mermaid
graph TD
    A[MudanÃ§a no cÃ³digo] --> B[GitHub Actions detecta]
    B --> C{Ã‰ Pull Request?}
    C -->|Sim| D[Executa ValidaÃ§Ã£o]
    C -->|NÃ£o| E[Executa Deploy]
    D --> F[Valida YAML e estrutura]
    E --> G[Converte YAML â†’ JSON]
    G --> H[Deploy no Databricks]
    F --> I[âœ… ValidaÃ§Ã£o OK]
    H --> J[âœ… Deploy OK]
```

### ğŸ¯ Ambientes e SeguranÃ§a

- âœ… **Ambiente**: `Databricks` configurado no GitHub
- âœ… **Secrets**: Armazenados de forma segura no ambiente
- âœ… **Acesso**: Controlado por permissÃµes do ambiente

### ğŸ“ Trigger do Pipeline

O pipeline Ã© executado automaticamente quando:

- âœ… **Push** para a branch `main`
- âœ… **Pull Request** para a branch `main`
- âœ… **MudanÃ§as** em arquivos especÃ­ficos:
  - `src/**` (qualquer arquivo na pasta src)
  - `.github/workflows/magic-deploy.yml`
  - `.github/DAGs/magic.yml`
  - `.github/scripts/**` (scripts de deploy e validaÃ§Ã£o)

---

## ğŸ”„ Pipeline de Dados

### ğŸ“Š Estrutura do Pipeline

```
STAGING â†’ BRONZE â†’ SILVER â†’ GOLD
   â†“        â†“        â†“       â†“
IngestÃ£o â†’ Raw â†’ Clean â†’ Analytics
```

### ğŸ”— DependÃªncias entre Tasks

- **Staging**: ExecuÃ§Ã£o paralela de todas as ingestÃµes
- **Bronze**: Depende do respectivo staging
- **Silver**: Depende do respectivo bronze
- **Gold**: Depende de mÃºltiplas tabelas silver

### âš¡ OtimizaÃ§Ãµes Delta

- âœ… Delta Preview habilitado
- âœ… OtimizaÃ§Ã£o de escrita automÃ¡tica
- âœ… Auto-compactaÃ§Ã£o habilitada

---

## ğŸ–¥ï¸ ConfiguraÃ§Ãµes de Cluster

### ğŸ“Š DESENVOLVIMENTO (ATUAL)

```yaml
# ConfiguraÃ§Ã£o atual em .github/DAGs/magic.yml
node_type_id: "m5d.large"      # 2 vCPUs, 8GB RAM
is_single_node: true           # Single node
autoscale:
  min_workers: 1               # MÃ­nimo 1 worker
  max_workers: 2               # MÃ¡ximo 2 workers
```

**ğŸ“ˆ EspecificaÃ§Ãµes:**
- **vCPUs**: 2
- **RAM**: 8GB
- **Custo**: ~$0.25/hora
- **Tempo estimado**: 2-3 horas (1000+ pÃ¡ginas)
- **Uso**: Desenvolvimento, testes, validaÃ§Ã£o

---

### ğŸš€ PRODUÃ‡ÃƒO RECOMENDADA

```yaml
# ConfiguraÃ§Ã£o recomendada para produÃ§Ã£o
node_type_id: "m5d.2xlarge"    # 8 vCPUs, 32GB RAM
is_single_node: false          # Multi-node
autoscale:
  min_workers: 3               # MÃ­nimo 3 workers
  max_workers: 6               # MÃ¡ximo 6 workers
```

**ğŸ“ˆ EspecificaÃ§Ãµes:**
- **vCPUs**: 8
- **RAM**: 32GB
- **Custo**: ~$1.00/hora
- **Tempo estimado**: 30-45 minutos (1000+ pÃ¡ginas)
- **Uso**: ProduÃ§Ã£o, ingestÃ£o intensiva

---

### ğŸ’° ALTERNATIVA ECONÃ”MICA

```yaml
# ConfiguraÃ§Ã£o econÃ´mica para produÃ§Ã£o
node_type_id: "m5d.large"      # 2 vCPUs, 8GB RAM
is_single_node: false          # Multi-node
autoscale:
  min_workers: 2               # MÃ­nimo 2 workers
  max_workers: 3               # MÃ¡ximo 3 workers
```

**ğŸ“ˆ EspecificaÃ§Ãµes:**
- **vCPUs**: 2
- **RAM**: 8GB
- **Custo**: ~$0.25/hora
- **Tempo estimado**: 1.5-2 horas (1000+ pÃ¡ginas)
- **Uso**: ProduÃ§Ã£o com orÃ§amento limitado

---

### ğŸ¯ ComparaÃ§Ã£o de Performance

| ConfiguraÃ§Ã£o | Tempo | Custo/ExecuÃ§Ã£o | RecomendaÃ§Ã£o |
|--------------|-------|----------------|--------------|
| **Desenvolvimento** | 2-3 horas | $0.50-$0.75 | âŒ Muito lento |
| **ProduÃ§Ã£o** | 1-1.5 horas | $0.50-$0.75 | âš ï¸ AceitÃ¡vel |
| **Alta Performance** | 30-45 min | $0.50-$0.75 | âœ… **RECOMENDADO** |
| **EconÃ´mica** | 1.5-2 horas | $0.38-$0.50 | ğŸ’° Alternativa |

### ğŸ”„ Como Migrar para ProduÃ§Ã£o

1. **Edite** o arquivo `.github/DAGs/magic.yml`
2. **Altere** as configuraÃ§Ãµes do cluster:
   ```yaml
   node_type_id: "m5d.2xlarge"  # Para alta performance
   is_single_node: false        # Multi-node
   autoscale:
     min_workers: 3
     max_workers: 6
   ```
3. **Commit e push** para `main`
4. **GitHub Actions** farÃ¡ o deploy automaticamente
5. **Monitore** a performance

---

## ğŸ• Agendamento

### â° ConfiguraÃ§Ã£o Atual

O pipeline estÃ¡ configurado para executar:
- **FrequÃªncia**: Diariamente
- **HorÃ¡rio**: 06:00 (America/Sao_Paulo)
- **Status**: UNPAUSED (ativo)

### ğŸ“… Cron Expression

```
"0 0 6 * * ?"
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â””â”€ Ano (opcional)
â”‚ â”‚ â”‚ â”‚ â”‚ â””â”€â”€â”€ Dia da semana (opcional)
â”‚ â”‚ â”‚ â”‚ â””â”€â”€â”€â”€â”€ MÃªs
â”‚ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€ Dia do mÃªs
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€ Hora
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Minuto
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Segundo
```

### ğŸ”§ Como Alterar o Agendamento

1. Edite o arquivo `.github/DAGs/magic.yml`
2. Localize a seÃ§Ã£o `schedule`
3. Modifique o `quartz_cron_expression`
4. Commit e push para `main`

---

## ğŸ› ï¸ Comandos Ãšteis

### ğŸ“Š Verificar Status do Job

```bash
# Listar todos os jobs
databricks jobs list --output JSON

# Filtrar apenas o MTG_PIPELINE
databricks jobs list --output JSON | jq -r '.jobs[] | select(.settings.name == "MTG_PIPELINE")'
```

### â–¶ï¸ Executar Job Manualmente

```bash
# Executar job especÃ­fico
databricks jobs run-now --job-id <JOB_ID>

# Executar e aguardar conclusÃ£o
databricks jobs run-now --job-id <JOB_ID> --wait
```

### ğŸ“‹ Ver Logs de ExecuÃ§Ã£o

```bash
# Ver detalhes de uma execuÃ§Ã£o
databricks jobs get-run --run-id <RUN_ID>

# Ver logs de uma execuÃ§Ã£o
databricks jobs get-run-output --run-id <RUN_ID>
```

### â¸ï¸ Pausar/Despausar Job

```bash
# Pausar job
databricks jobs pause --job-id <JOB_ID>

# Despausar job
databricks jobs unpause --job-id <JOB_ID>
```

### ğŸ”„ Deploy Manual

```bash
# Deploy via script Python
python .github/scripts/deploy.py

# Deploy direto via CLI
databricks jobs create --json @.github/DAGs/magic.json
```

---

## ğŸ” Monitoramento

### ğŸ“ˆ GitHub Actions

- **Acesse**: Aba `Actions` no repositÃ³rio
- **Visualize**: HistÃ³rico de deploys
- **Verifique**: Logs de erro
- **Configure**: NotificaÃ§Ãµes de falha

### ğŸ¢ Databricks

- **Acesse**: `Jobs` no workspace
- **Monitore**: ExecuÃ§Ãµes em tempo real
- **Configure**: Alertas de falha
- **Analise**: MÃ©tricas de performance

### ğŸ“Š MÃ©tricas Importantes

- **Tempo de execuÃ§Ã£o** por task
- **Taxa de sucesso** do pipeline
- **Uso de recursos** do cluster
- **FrequÃªncia de falhas**

---

## ğŸš¨ Troubleshooting

### âŒ Erro: "Invalid YAML"

**Sintomas:**
- Workflow falha na validaÃ§Ã£o
- Erro de sintaxe YAML

**SoluÃ§Ã£o:**
1. Verifique a sintaxe do `magic.yml`
2. Use um validador YAML online
3. Verifique indentaÃ§Ã£o e caracteres especiais

### ğŸ” Erro: "Authentication failed"

**Sintomas:**
- Erro 401/403 no deploy
- Falha de autenticaÃ§Ã£o

**SoluÃ§Ã£o:**
1. Verifique se os secrets estÃ£o configurados
2. Confirme se o token nÃ£o expirou
3. Verifique permissÃµes no Databricks

### ğŸ” Erro: "Job not found"

**Sintomas:**
- Erro ao tentar atualizar job
- Job nÃ£o existe no Databricks

**SoluÃ§Ã£o:**
1. O job serÃ¡ criado automaticamente na primeira execuÃ§Ã£o
2. Verifique se o nome do job estÃ¡ correto
3. Execute deploy manual se necessÃ¡rio

### âš¡ Erro: "Cluster not available"

**Sintomas:**
- Falha ao iniciar cluster
- Timeout na criaÃ§Ã£o

**SoluÃ§Ã£o:**
1. Verifique as configuraÃ§Ãµes do cluster
2. Confirme se hÃ¡ recursos disponÃ­veis na conta
3. Verifique limites de quota

### ğŸ“ Erro: "Notebook not found"

**Sintomas:**
- Falha na validaÃ§Ã£o de paths
- Notebook nÃ£o encontrado

**SoluÃ§Ã£o:**
1. Verifique se o notebook existe no caminho especificado
2. Confirme se o path estÃ¡ correto no `magic.yml`
3. Verifique se o arquivo foi commitado

---

## ğŸ“ Suporte

### ğŸ†˜ Onde Buscar Ajuda

Para problemas relacionados ao:

- **GitHub Actions**: Verifique os logs na aba Actions
- **Databricks**: Consulte a documentaÃ§Ã£o oficial
- **Pipeline de dados**: Verifique os logs de execuÃ§Ã£o no Databricks

### ğŸ“š Recursos Ãšteis

- [GitHub Actions Documentation](https://docs.github.com/en/actions)
- [Databricks CLI Documentation](https://docs.databricks.com/dev-tools/cli/index.html)
- [Databricks Jobs API](https://docs.databricks.com/dev-tools/api/latest/jobs.html)

### ğŸ› Como Reportar Bugs

1. **Capture logs** completos do erro
2. **Descreva** o que estava tentando fazer
3. **Inclua** contexto do ambiente
4. **Mencione** se Ã© reproduzÃ­vel

---

## ğŸ”„ AtualizaÃ§Ãµes

### ğŸ“ Como Atualizar o Pipeline

1. **FaÃ§a as mudanÃ§as** nos notebooks
2. **Commit e push** para `main`
3. **GitHub Actions** farÃ¡ o deploy automaticamente
4. **Monitore** a execuÃ§Ã£o
5. **Verifique** se tudo funcionou

### ğŸ”„ Processo de Deploy

```
Desenvolvimento â†’ Teste â†’ ValidaÃ§Ã£o â†’ Deploy â†’ Monitoramento
     â†“              â†“         â†“         â†“         â†“
   Notebooks    ValidaÃ§Ã£o   GitHub   Databricks  Logs
```

---

## ğŸ“Š Status do Projeto

### âœ… Funcionalidades Implementadas

- [x] CI/CD automatizado
- [x] ValidaÃ§Ã£o de YAML
- [x] Deploy inteligente (criar/atualizar)
- [x] Monitoramento de execuÃ§Ã£o
- [x] Tratamento de erros
- [x] DocumentaÃ§Ã£o completa
