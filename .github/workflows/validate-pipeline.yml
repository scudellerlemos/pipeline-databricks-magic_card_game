name: CI/CD Pipeline - Magic Card Game

on:
  pull_request:
    branches: [ main ]
    paths:
      - 'src/**'
      - '.github/DAGs/**'
      - '.github/workflows/**'
      - '.github/scripts/**'
  push:
    branches: [ main ]
    paths:
      - 'src/**'
      - '.github/DAGs/**'
      - '.github/workflows/**'
      - '.github/scripts/**'

env:
  DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
  DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

jobs:
  # ============================================================================
  # VALIDA√á√ïES DURANTE PR
  # ============================================================================
  validate:
    runs-on: ubuntu-latest
    environment: Databricks
    permissions:
      contents: read
      pull-requests: write
      issues: write
      id-token: write
      checks: write
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        pip install pyyaml jsonschema databricks-cli jq
        
    - name: Validate YAML syntax
      run: |
        python -c "import yaml; yaml.safe_load(open('.github/DAGs/magic.yml', 'r'))"
        echo "‚úÖ YAML syntax is valid"
        
    - name: Validate pipeline structure
      run: |
        python -c "
        import yaml
        import sys
        
        with open('.github/DAGs/magic.yml', 'r') as f:
            config = yaml.safe_load(f)
        
        # Check if jobs exist
        if 'resources' not in config or 'jobs' not in config['resources']:
            print('‚ùå No jobs found in configuration')
            sys.exit(1)
            
        # Check if MTG_PIPELINE exists
        if 'MTG_PIPELINE' not in config['resources']['jobs']:
            print('‚ùå MTG_PIPELINE job not found')
            sys.exit(1)
            
        job = config['resources']['jobs']['MTG_PIPELINE']
        
        # Check required fields
        required_fields = ['name', 'tasks', 'job_clusters', 'git_source']
        for field in required_fields:
            if field not in job:
                print(f'‚ùå Missing required field: {field}')
                sys.exit(1)
                
        # Check if tasks exist
        if not job['tasks']:
            print('‚ùå No tasks defined')
            sys.exit(1)
            
        # Check task dependencies
        task_keys = [task['task_key'] for task in job['tasks']]
        for task in job['tasks']:
            if 'depends_on' in task:
                for dep in task['depends_on']:
                    if dep['task_key'] not in task_keys:
                        print(f'‚ùå Task {task[\"task_key\"]} depends on non-existent task: {dep[\"task_key\"]}')
                        sys.exit(1)
                        
        print('‚úÖ Pipeline structure is valid')
        print(f'üìä Total tasks: {len(job[\"tasks\"])}')
        "
        
    - name: Check notebook paths
      run: |
        python -c "
        import yaml
        import os
        import sys
        
        with open('.github/DAGs/magic.yml', 'r') as f:
            config = yaml.safe_load(f)
            
        job = config['resources']['jobs']['MTG_PIPELINE']
        
        missing_notebooks = []
        for task in job['tasks']:
            if 'notebook_task' in task:
                notebook_path = task['notebook_task']['notebook_path']
                # Remove .ipynb extension if present
                if notebook_path.endswith('.ipynb'):
                    notebook_path = notebook_path[:-6]
                    
                # Check if notebook exists
                if not os.path.exists(f'{notebook_path}.ipynb'):
                    missing_notebooks.append(f'{notebook_path}.ipynb')
                    
        if missing_notebooks:
            print('‚ùå Missing notebooks:')
            for notebook in missing_notebooks:
                print(f'  - {notebook}')
            sys.exit(1)
                    
        print('‚úÖ All notebook paths are valid')
        "
        
    - name: Validate cluster configuration
      run: |
        python -c "
        import yaml
        import sys
        
        with open('.github/DAGs/magic.yml', 'r') as f:
            config = yaml.safe_load(f)
            
        job = config['resources']['jobs']['MTG_PIPELINE']
        
        # Check cluster configuration
        if 'job_clusters' not in job:
            print('‚ùå No job clusters defined')
            sys.exit(1)
            
        for cluster in job['job_clusters']:
            if 'new_cluster' not in cluster:
                print('‚ùå Cluster configuration missing new_cluster section')
                sys.exit(1)
                
            cluster_config = cluster['new_cluster']
            required_cluster_fields = ['spark_version', 'node_type_id']
            
            for field in required_cluster_fields:
                if field not in cluster_config:
                    print(f'‚ùå Missing required cluster field: {field}')
                    sys.exit(1)
                    
        print('‚úÖ Cluster configuration is valid')
        "
        
    - name: Check git configuration
      run: |
        python -c "
        import yaml
        import sys
        
        with open('.github/DAGs/magic.yml', 'r') as f:
            config = yaml.safe_load(f)
            
        job = config['resources']['jobs']['MTG_PIPELINE']
        
        if 'git_source' not in job:
            print('‚ùå Git source not configured')
            sys.exit(1)
            
        git_config = job['git_source']
        required_git_fields = ['git_url', 'git_provider', 'git_branch']
        
        for field in required_git_fields:
            if field not in git_config:
                print(f'‚ùå Missing required git field: {field}')
                sys.exit(1)
                
        print('‚úÖ Git configuration is valid')
        "
        
    - name: Validate notebook syntax
      run: |
        python -c "
        import yaml
        import json
        import os
        import sys
        
        with open('.github/DAGs/magic.yml', 'r') as f:
            config = yaml.safe_load(f)
            
        job = config['resources']['jobs']['MTG_PIPELINE']
        
        invalid_notebooks = []
        for task in job['tasks']:
            if 'notebook_task' in task:
                notebook_path = task['notebook_task']['notebook_path']
                if notebook_path.endswith('.ipynb'):
                    notebook_path = notebook_path[:-6]
                    
                notebook_file = f'{notebook_path}.ipynb'
                try:
                    with open(notebook_file, 'r') as f:
                        notebook_data = json.load(f)
                    
                    # Check if notebook has cells
                    if 'cells' not in notebook_data:
                        invalid_notebooks.append(f'{notebook_file} - No cells found')
                        continue
                        
                    # Check if notebook has at least one code cell
                    code_cells = [cell for cell in notebook_data['cells'] if cell.get('cell_type') == 'code']
                    if not code_cells:
                        invalid_notebooks.append(f'{notebook_file} - No code cells found')
                        
                except json.JSONDecodeError:
                    invalid_notebooks.append(f'{notebook_file} - Invalid JSON')
                except Exception as e:
                    invalid_notebooks.append(f'{notebook_file} - {str(e)}')
                    
        if invalid_notebooks:
            print('‚ùå Invalid notebooks:')
            for notebook in invalid_notebooks:
                print(f'  - {notebook}')
            sys.exit(1)
                    
        print('‚úÖ All notebook syntax is valid')
        "
        
    - name: Generate validation report
      run: |
        python -c "
        import yaml
        from datetime import datetime
        
        with open('.github/DAGs/magic.yml', 'r') as f:
            config = yaml.safe_load(f)
            
        job = config['resources']['jobs']['MTG_PIPELINE']
        
        print('üìã Pipeline Validation Report')
        print('=' * 50)
        print(f'Job Name: {job[\"name\"]}')
        print(f'Description: {job[\"description\"]}')
        print(f'Total Tasks: {len(job[\"tasks\"])}')
        print(f'Schedule: {job[\"schedule\"][\"quartz_cron_expression\"]}')
        print(f'Timezone: {job[\"schedule\"][\"timezone_id\"]}')
        print(f'Status: {job[\"schedule\"][\"pause_status\"]}')
        print()
        
        print('üìÅ Task Breakdown:')
        task_types = {}
        for task in job['tasks']:
            task_type = task['task_key'].split('_')[0]
            task_types[task_type] = task_types.get(task_type, 0) + 1
            
        for task_type, count in task_types.items():
            print(f'  {task_type}: {count} tasks')
            
        print()
        print('üîó Dependencies:')
        for task in job['tasks']:
            if 'depends_on' in task:
                deps = [dep['task_key'] for dep in task['depends_on']]
                print(f'  {task[\"task_key\"]} ‚Üí {deps}')
                
        print()
        print('‚úÖ Validation completed successfully!')
        print(f'üìÖ Generated: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')
        "
        
    - name: Comment PR with validation results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const comment = `## ‚úÖ Valida√ß√£o do Pipeline Conclu√≠da
          
          ### üìä Resumo da Valida√ß√£o:
          - ‚úÖ Sintaxe YAML v√°lida
          - ‚úÖ Estrutura do pipeline v√°lida
          - ‚úÖ Caminhos dos notebooks verificados
          - ‚úÖ Configura√ß√£o do cluster v√°lida
          - ‚úÖ Configura√ß√£o Git v√°lida
          - ‚úÖ Sintaxe dos notebooks v√°lida
          
          üöÄ **Pipeline pronto para deploy!**
          
          ---
          *Valida√ß√£o executada em: ${new Date().toLocaleString('pt-BR')}*`;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });

  # ============================================================================
  # DEPLOY AUTOM√ÅTICO AP√ìS APROVA√á√ÉO DA PR
  # ============================================================================
  deploy:
    needs: validate
    runs-on: ubuntu-latest
    environment: Databricks
    permissions:
      contents: read
      pull-requests: write
      issues: write
      id-token: write
      checks: write
    
    # S√≥ executa quando a PR √© aprovada e mergeada na main
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        pip install databricks-cli pyyaml jq
        
    - name: Configure Databricks CLI
      run: |
        echo "DATABRICKS_HOST=$DATABRICKS_HOST" >> $GITHUB_ENV
        echo "DATABRICKS_TOKEN=$DATABRICKS_TOKEN" >> $GITHUB_ENV
        
    - name: Validate Databricks connection
      run: |
        databricks --version
        databricks jobs list --output JSON | head -20
        
    - name: Deploy to Databricks
      run: |
        echo "üöÄ Iniciando deploy do pipeline..."
        python .github/scripts/deploy.py
        
    - name: Verify deployment
      run: |
        echo "‚è≥ Aguardando 30 segundos para verificar o deploy..."
        sleep 30
        
        echo "üîç Verificando status do job..."
        databricks jobs list --output JSON | jq -r '.jobs[] | select(.settings.name == "MTG_PIPELINE") | "Job ID: \(.job_id), Status: \(.settings.schedule.pause_status)"'
        
        # Get job details
        job_info=$(databricks jobs list --output JSON | jq -r '.jobs[] | select(.settings.name == "MTG_PIPELINE")')
        if [ -n "$job_info" ]; then
          echo "‚úÖ Job encontrado e configurado corretamente"
        else
          echo "‚ùå Job n√£o encontrado"
          exit 1
        fi
        
    - name: Create deployment summary
      run: |
        echo "## üöÄ Deploy Conclu√≠do com Sucesso!" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### üìã Detalhes do Deploy:" >> $GITHUB_STEP_SUMMARY
        echo "- ‚úÖ Pipeline validado" >> $GITHUB_STEP_SUMMARY
        echo "- ‚úÖ Conex√£o com Databricks estabelecida" >> $GITHUB_STEP_SUMMARY
        echo "- ‚úÖ Job criado/atualizado no Databricks" >> $GITHUB_STEP_SUMMARY
        echo "- ‚úÖ Verifica√ß√£o de status conclu√≠da" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "üéâ **Pipeline em produ√ß√£o!**" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "üìÖ Deploy realizado em: $(date '+%Y-%m-%d %H:%M:%S')" >> $GITHUB_STEP_SUMMARY
        
    - name: Create deployment status
      if: github.event_name == 'push'
      uses: actions/github-script@v7
      with:
        script: |
          const deployment = await github.rest.repos.createDeployment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            ref: context.sha,
            environment: 'production',
            description: 'Deploy do pipeline MTG para Databricks',
            auto_merge: false,
            required_contexts: []
          });
          
          await github.rest.repos.createDeploymentStatus({
            owner: context.repo.owner,
            repo: context.repo.repo,
            deployment_id: deployment.data.id,
            state: 'success',
            description: 'Pipeline deployado com sucesso no Databricks',
            environment_url: process.env.DATABRICKS_HOST
          });
