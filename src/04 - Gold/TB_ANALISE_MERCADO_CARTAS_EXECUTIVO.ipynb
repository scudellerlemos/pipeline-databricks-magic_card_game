{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0a44498-e73a-4a34-b0ea-ba56690e2c3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Camada Gold - Análise Mercado Cartas Executivo - Magic: The Gathering\n",
    "# Pipeline 100% PySpark DataFrame API\n",
    "# Seguindo padrão Silver com Unity Catalog e merge incremental\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# BIBLIOTECAS UTILIZADAS\n",
    "# ============================================================================\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "# ============================================================================\n",
    "# FUNÇÕES UTILITÁRIAS\n",
    "# ============================================================================\n",
    "def get_secret(secret_name, default_value=None):\n",
    "    \"\"\"Obtém segredos do Databricks Secret Scope\"\"\"\n",
    "    try:\n",
    "        return dbutils.secrets.get(scope=\"mtg-pipeline\", key=secret_name)\n",
    "    except:\n",
    "        if default_value is not None:\n",
    "            print(f\"Secret '{secret_name}' não encontrado, usando valor padrão\")\n",
    "            return default_value\n",
    "        else:\n",
    "            print(f\"Secret obrigatório '{secret_name}' não encontrado\")\n",
    "            raise Exception(f\"Required secret '{secret_name}' not configured\")\n",
    "\n",
    "def setup_unity_catalog(catalog, schema):\n",
    "    \"\"\"Configura Unity Catalog\"\"\"\n",
    "    try:\n",
    "        spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog}\")\n",
    "        spark.sql(f\"USE CATALOG {catalog}\")\n",
    "        spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema}\")\n",
    "        spark.sql(f\"USE SCHEMA {schema}\")\n",
    "        print(f\"✅ Schema {catalog}.{schema} configurado com sucesso\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao configurar Unity Catalog: {e}\")\n",
    "        return False\n",
    "\n",
    "def load_to_gold_unity_incremental(df_final, catalog, schema, table_name, s3_gold_path):\n",
    "    \"\"\"Carrega dados na camada Gold com suporte a Unity Catalog\"\"\"\n",
    "    delta_path = f\"s3://{s3_gold_path}/{table_name}\"\n",
    "    full_table_name = f\"{catalog}.{schema}.{table_name}\"\n",
    "    \n",
    "    print(f\"Salvando dados em: {delta_path}\")\n",
    "    print(f\"Qtd linhas df_final: {df_final.count()}\")\n",
    "    \n",
    "    try:\n",
    "        # Sobrescrever para análises (dados agregados)\n",
    "        df_final.write.format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"overwriteSchema\", \"true\") \\\n",
    "            .partitionBy(\"DATA_REF\") \\\n",
    "            .save(delta_path)\n",
    "        \n",
    "        # Criar/atualizar tabela Unity Catalog\n",
    "        try:\n",
    "            spark.sql(f\"SELECT 1 FROM {full_table_name} LIMIT 1\")\n",
    "            print(f\"ℹ️ Tabela Unity Catalog '{full_table_name}' já existe\")\n",
    "        except:\n",
    "            spark.sql(f\"\"\"\n",
    "                CREATE TABLE {full_table_name}\n",
    "                USING DELTA\n",
    "                LOCATION '{delta_path}'\n",
    "            \"\"\")\n",
    "            print(f\"✅ Tabela Unity Catalog criada: {full_table_name}\")\n",
    "        \n",
    "        print(\"✅ Dados salvos com sucesso!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao salvar dados: {e}\")\n",
    "        raise\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURAÇÃO E VARIÁVEIS\n",
    "# ============================================================================\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Usar secrets para configuração\n",
    "CATALOG_NAME = get_secret(\"catalog_name\")\n",
    "SCHEMA_SILVER = \"silver\"\n",
    "SCHEMA_GOLD = \"gold\"\n",
    "TABLE_NAME = \"TB_ANALISE_MERCADO_CARTAS_EXECUTIVO\"\n",
    "S3_BUCKET = get_secret(\"s3_bucket\")\n",
    "S3_GOLD_PREFIX = get_secret(\"s3_gold_prefix\", \"magic_the_gathering/gold\")\n",
    "S3_GOLD_PATH = f\"{S3_BUCKET}/{S3_GOLD_PREFIX}\"\n",
    "\n",
    "# Configurar Unity Catalog\n",
    "setup_unity_catalog(CATALOG_NAME, SCHEMA_GOLD)\n",
    "\n",
    "# Inicialização Spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# ============================================================================\n",
    "# Leitura das Tabelas Silver\n",
    "# ============================================================================\n",
    "df_cards = spark.table(f\"{CATALOG_NAME}.{SCHEMA_SILVER}.TB_FATO_SILVER_CARDS\").alias(\"cards\")\n",
    "df_prices = spark.table(f\"{CATALOG_NAME}.{SCHEMA_SILVER}.TB_FATO_SILVER_CARDPRICES\").alias(\"prices\")\n",
    "\n",
    "# ============================================================================\n",
    "# Join Cards + Prices pela chave comum\n",
    "# ============================================================================\n",
    "# Cards tem: NME_CARD, NME_SET, COD_SET, NME_CARD_TYPE, NME_RARITY, NME_ARTIST, DT_INGESTION\n",
    "# Prices tem: NME_CARD, COD_SET, VLR_USD, VLR_EUR, VLR_TIX, NME_RARITY, DT_INGESTION\n",
    "df = df_cards.join(df_prices, [\"NME_CARD\", \"COD_SET\"], \"inner\")\n",
    "\n",
    "# ============================================================================\n",
    "# Inclusão de colunas de interesse\n",
    "# ============================================================================\n",
    "# Usar DT_INGESTION da tabela cards (mais confiável para datas das cartas)\n",
    "df = df.withColumn(\"DATA_REF\", trunc(df_cards[\"DT_INGESTION\"], \"month\"))\n",
    "\n",
    "# ============================================================================\n",
    "# KPIs por raridade, artista, coleção e tipo de carta\n",
    "# ============================================================================\n",
    "# JOIN resolve conflito de NME_RARITY: usar a coluna do cards (mais confiável)\n",
    "df_gold = (\n",
    "    df.groupBy(\"DATA_REF\", \"NME_SET\", \"NME_CARD_TYPE\", \"cards.NME_RARITY\", \"NME_ARTIST\")\n",
    "      .agg(\n",
    "          sum(\"VLR_USD\").alias(\"VALOR_TOTAL_MERCADO\"),\n",
    "          countDistinct(\"NME_CARD\").alias(\"QTD_CARTAS_ATIVAS\"),\n",
    "          avg(\"VLR_USD\").alias(\"VALOR_MEDIO_CARTA\"),\n",
    "          expr(\"percentile_approx(VLR_USD, 0.5)\").alias(\"TICKET_MEDIANA\")\n",
    "      )\n",
    "      .withColumnRenamed(\"cards.NME_RARITY\", \"NME_RARITY\")  # Rename para remover prefixo\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# Market share por set\n",
    "# ============================================================================\n",
    "from pyspark.sql.window import Window\n",
    "window_set = Window.partitionBy(\"DATA_REF\")\n",
    "df_gold = df_gold.withColumn(\n",
    "    \"MARKET_SHARE_SET\",\n",
    "    col(\"VALOR_TOTAL_MERCADO\") / sum(\"VALOR_TOTAL_MERCADO\").over(window_set)\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# Top N cartas por valorização/desvalorização (exemplo para N=3)\n",
    "# ============================================================================\n",
    "window_card = Window.partitionBy(\"NME_CARD\").orderBy(\"DATA_REF\")\n",
    "df_val = (\n",
    "    df.groupBy(\"DATA_REF\", \"NME_CARD\")\n",
    "      .agg(sum(\"VLR_USD\").alias(\"VALOR_ATUAL\"))\n",
    "      .withColumn(\"VALOR_ANTERIOR\", lag(\"VALOR_ATUAL\").over(window_card))\n",
    "      .withColumn(\"VARIACAO_PERC_VALOR\", \n",
    "                  when(col(\"VALOR_ANTERIOR\").isNotNull() & (col(\"VALOR_ANTERIOR\") != 0),\n",
    "                       (col(\"VALOR_ATUAL\") - col(\"VALOR_ANTERIOR\")) / col(\"VALOR_ANTERIOR\"))\n",
    "                  .otherwise(lit(None)))\n",
    ")\n",
    "window_risco = Window.partitionBy(\"DATA_REF\").orderBy(col(\"VARIACAO_PERC_VALOR\").desc())\n",
    "df_val = df_val.withColumn(\"RANK_VALORIZACAO\", row_number().over(window_risco))\n",
    "df_val = df_val.withColumn(\n",
    "    \"TIPO_VARIACAO\",\n",
    "    when(col(\"VARIACAO_PERC_VALOR\") > 0, \"Valorização\")\n",
    "    .when(col(\"VARIACAO_PERC_VALOR\") < 0, \"Desvalorização\")\n",
    "    .otherwise(\"Estável\")\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# Escrita da Tabela de Análise Executiva (única saída deste script)\n",
    "# ============================================================================\n",
    "load_to_gold_unity_incremental(\n",
    "    df_final=df_gold,\n",
    "    catalog=CATALOG_NAME,\n",
    "    schema=SCHEMA_GOLD,\n",
    "    table_name=TABLE_NAME,\n",
    "    s3_gold_path=S3_GOLD_PATH\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# Fim do Script\n",
    "# ============================================================================\n",
    "print(\"TB_ANALISE_MERCADO_CARTAS_EXECUTIVO criado com sucesso!\")\n",
    "print(\"KPIs executivos consolidados!\")\n",
    "print(\"Padrão Silver aplicado: Unity Catalog + Secrets + Delta!\")\n",
    "print(f\"Tabela criada: {CATALOG_NAME}.{SCHEMA_GOLD}.{TABLE_NAME}\") "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "TB_ANALISE_MERCADO_CARTAS_EXECUTIVO",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
